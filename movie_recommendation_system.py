# -*- coding: utf-8 -*-
"""Movie_Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11IPajJAI7kK3rsPDRZjkOljGFI-DYmx2
"""

import numpy as np
import pandas as pd
import ast

movies = pd.read_csv('/content/tmdb_5000_movies.csv')
credits = pd.read_csv('/content/tmdb_5000_credits.csv')

movies.head(1)

credits.head(1)

#JOIN BOth dataset
movies.merge(credits, on='title')

movies.merge(credits, on='title').shape

movies.shape

credits.shape

movies = movies.merge(credits, on= 'title')

movies.head(1)

#colums that are useful
#genres, id, keywords, title, overview, cast, crew
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

movies.head(1)

#now we will merge overview, genres, keywords etc. in one column so that we can get paragraph and we will take
# top 3 names of cast and only director name from crew
#preprocessing

#movies which does not have overview
movies.isnull().sum()

#means we have 3 movies that does not have overview, so we will drop these movies
movies.dropna(inplace = True)

#check if there is any duplicate function
movies.duplicated().sum()

#genres are in the format of
movies.iloc[0].genres

#we have to convert this in
#['Action', 'Adventure', 'Fantasy', 'SciFI']

def convert(obj):
    L = []
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L

#ast.literal_eval(obj) this function converted string list into list
movies['genres']

movies['genres'] = movies['genres'].apply(convert)

movies.head()

movies['keywords'] = movies['keywords'].apply(convert)

movies.head()

def convert3(obj):
    L = []
    counter = 0
    for i in ast.literal_eval(obj):
        if counter != 3:
            L.append(i['name'])
            counter += 1
        else:
            break
    return L

movies['cast'] = movies['cast'].apply(convert3)

movies.head()

def fetch_director(obj):
    L = []
    for i in ast.literal_eval(obj):
        if i['job'] == 'Director':
            L.append(i['name'])
            break
    return L

movies['crew'] = movies['crew'].apply(fetch_director)

movies.head()

#we have overview in form of string
movies['overview'][0]

#we will convert this into list so that we can corrdinate with other columns
movies['overview'] = movies['overview'].apply(lambda x: x.split())

movies.head()

# 'Sam Worthington' = 'SamWorthington'
movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])

movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])

movies['cast'] = movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])

movies['crew'] = movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])

movies['tags'] = movies['overview']+ movies['genres']+ movies['keywords']+ movies['cast']+ movies['crew']

new_df = movies[['movie_id', 'title','tags']]

new_df

#convertt list into string
new_df['tags'] = new_df['tags'].apply(lambda x: " ".join(x))

new_df['tags'][0]

#convert into lower case
new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())

new_df.head()

import nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)

new_df['tags'] = new_df['tags'].apply(stem)

new_df['tags'][0]

new_df['tags'][1]

#converting tags to array
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000, stop_words='english')

vectors = cv.fit_transform(new_df['tags']).toarray()

vectors

vectors[0]

#5000 words
cv.get_feature_names_out()

ps.stem('loving')

from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)

#it is showing the distance between 1st with every other movie
similarity[0]

def recommend(movie):
    movie_index = new_df[new_df['title'] == movie].index[0]
    distances = similarity[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True,key=lambda x:x[1])[1:6]

    for i in movies_list:
        print(new_df.iloc[i[0]].title)
        #print(i[0])

recommend('Batman Begins')

new_df.iloc[1216].title

#fetching index of any movie
new_df[new_df['title'] == 'Batman Begins'].index[0]

#can sort distance in reverse order by using
#sorted(similarity[0], reverse = True)
#but we are losing index here with every movie , so we will now form a tuple
sorted(list(enumerate(similarity[0])), reverse=True,key=lambda x:x[1])[1:6]
#sorted with second element of tuple

import pickle

pickle.dump(new_df, open('movies.pkl','wb'))

new_df['title'].values

pickle.dump(similarity, open('similarity.pkl', 'wb'))

pickle.dump(new_df.to_dict(), open('movie_dict.pkl','wb'))

